{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# L4: Enhancing Cache Effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you‚Äôll learn several techniques to make your cache more accurate‚Äîlike threshold tuning, cross-encoders, LLM checks, and fuzzy matching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from cache.cross_encoder import CrossEncoder\n",
    "from cache.faq_data_container import FAQDataContainer\n",
    "from cache.llm_evaluator import LLMEvaluator\n",
    "from cache.wrapper import SemanticCacheWrapper\n",
    "from cache.evals import CacheEvaluator\n",
    "from cache.config import config\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì¶ Libraries and evaluation utilities imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Load data and setup cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_wrapper = SemanticCacheWrapper.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_container = FAQDataContainer()\n",
    "\n",
    "test_queries = data_container.test_df[\"question\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_wrapper.hydrate_from_df(data_container.faq_df)\n",
    "cache_results = cache_wrapper.check_many(\n",
    "    test_queries, distance_threshold=0.3\n",
    ")\n",
    "\n",
    "evaluator = CacheEvaluator(\n",
    "    true_labels=data_container.label_cache_hits(cache_results),\n",
    "    cache_results=cache_results,\n",
    ")\n",
    "evaluator.report_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Threshold sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_results = cache_wrapper.check_many(\n",
    "    test_queries, distance_threshold=1\n",
    ")\n",
    "evaluator = CacheEvaluator.from_full_retrieval(\n",
    "    true_labels=data_container.label_cache_hits(cache_results),\n",
    "    cache_results=cache_results,\n",
    ")\n",
    "\n",
    "evaluator.report_threshold_sweep(\n",
    "    metric_to_maximize=\"f1_score\",\n",
    "    metrics_to_plot=[\"f1_score\", \"precision\", \"recall\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cross Encoder Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cross encoder for reranking\n",
    "cross_encoder = CrossEncoder(\"Alibaba-NLP/gte-reranker-modernbert-base\")\n",
    "\n",
    "# Register cross encoder as a reranker with the cache wrapper\n",
    "cache_wrapper.register_reranker(cross_encoder.create_reranker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cross encoder directly (for demonstration)\n",
    "cross_encoder.predict(\n",
    "    [\n",
    "        \"what is the capital of China?\",\n",
    "        \"how to implement quick sort in python?\",\n",
    "        \"how to implement quick sort in python?\",\n",
    "    ],\n",
    "    [\"Beijing\", \"Introduction of quick sort\", \"The weather is nice today\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The bank raised its interest rates.\",\n",
    "    \"The river overflowed near the bank after heavy rain.\"\n",
    "]\n",
    "\n",
    "langcache_distance = cache_wrapper.pair_distance(\n",
    "    sentences[0], sentences[1]\n",
    ")\n",
    "cross_encoder_distance = cross_encoder.pair_distance(\n",
    "    sentences[0], sentences[1]\n",
    ")\n",
    "\n",
    "langcache_distance, cross_encoder_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_results = cache_wrapper.check_many(\n",
    "    test_queries,\n",
    "    distance_threshold=1,\n",
    "    num_results=10,\n",
    "    use_reranker_distance=True,\n",
    ")\n",
    "evaluator = CacheEvaluator.from_full_retrieval(\n",
    "    true_labels=data_container.label_cache_hits(cache_results),\n",
    "    cache_results=cache_results,\n",
    ")\n",
    "\n",
    "evaluator.report_threshold_sweep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## LLM Reranking in a Tiered System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cache.config import load_openai_key\n",
    "\n",
    "load_openai_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLMEvaluator.construct_with_gpt()\n",
    "\n",
    "cache_wrapper.clear_reranker()\n",
    "cache_wrapper.register_reranker(llm.create_reranker(batch_size=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_results = cache_wrapper.check_many(\n",
    "    test_queries,\n",
    "    distance_threshold=0.2828,\n",
    "    num_results=1,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = CacheEvaluator.from_full_retrieval(\n",
    "    true_labels=data_container.label_cache_hits(cache_results),\n",
    "    cache_results=cache_results,\n",
    ")\n",
    "\n",
    "evaluator.report_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output visualizations generated may differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzify_string(str, its=3):\n",
    "    for i in range(its):\n",
    "        str_list = list(str)\n",
    "        i = np.random.randint(0, len(str) - 1)\n",
    "        str_list[i], str_list[i + 1] = str_list[i + 1], str_list[i]\n",
    "        str = \"\".join(str_list)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_queries = []\n",
    "valid_query_map = set()\n",
    "for q in data_container.faq_df[\"question\"].tolist():\n",
    "    for dificulty in [2, 3, 4, 10, 10000]:\n",
    "        new_entry = fuzzify_string(q, dificulty)\n",
    "        fuzzy_queries.append(new_entry)\n",
    "        valid_query_map.add((new_entry, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_queries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cache.fuzzy_cache import FuzzyCache\n",
    "\n",
    "fuzzy_cache = FuzzyCache()\n",
    "fuzzy_cache.hydrate_from_df(data_container.faq_df)\n",
    "fuzzy_retrievals = fuzzy_cache.check_many(fuzzy_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_retrievals[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fuzzy_labeling = [\n",
    "    (r.query, r.matches[0].prompt) in valid_query_map if len(r.matches) > 0 else False\n",
    "    for r in fuzzy_retrievals\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CacheEvaluator.from_full_retrieval(\n",
    "    true_labels=valid_fuzzy_labeling,\n",
    "    cache_results=fuzzy_retrievals,\n",
    ").report_metrics(distance_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_wrapper.cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
